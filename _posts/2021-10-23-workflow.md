---
title: '[DL] 머신러닝의 작업흐름 일반'
categories:
    - ML

tag:
    - Python
    - Project
    - ML
    - Machine Learning
    - Deep Learning

last_modified_at: 2021-10-23T14:00:00+09:00
use_math: true
comments: true
toc: true
---

# 머신러닝의 작업 흐름 일반

보통 처음 머신러닝을 배울 때는 주로 제공되는 데이터셋이 항상 존재했었고 그 데이터셋을 이용하여 모델훈련을 했다. 하지만 현실은 그렇지 않은 경우가 많다. 제공되는 데이터셋부터 직면하는 것이 아니고, 문제부터 직면하게 되는 것이다.

당신이 머신러닝 컨설팅 가게를 창업한다고 상상해 보세요. 회사를 설립하고, 멋진 웹사이트를 만들고, 네트워크에 알린다. 그럼 다양한 프로젝트가 굴러 들어오기 시작할 것 이다. 밑에 있는 것들이 그 예시이다.

* 사진 공유 소셜 네트워크를 위한 개인 맞춤형 사진 검색 엔진
("결혼식"을 입력하면 별도의 태그가 필요없이 결혼식 때 찍었던 모든 사진을 검색.)

* 게시물 사이에 스팸과 부적절한 텍스트 콘텐츠를 표시하는 채팅 어플리케이션.

* 온라인 라디오 사용자를 위한 음악 추천 시스템.

* 전자상거래 웹 사이트에 대한 신용 카드 사기 탐지.

* 주어진 시간에 주어진 사용자에게 어떤 광고를 제공할 것인지 결정하기 위해 디스플레이 광고 클릭률 예측.

* 쿠키 제조 라인의 컨베이어 벨트에 불량 쿠키 항목을 지정하여 분류.

* 아직 알려지지 않은 고고학 유적지의 위치를 예측하기 위해 위성 사진 사용.

## 윤리에 관한 참고 사항

'얼굴 사진으로 누군가의 신뢰도를 평가하는 AI 구축'과 같이 윤리적으로 의심스러운 프로젝트를 제안받기도 한다. 

무엇보다도, 이 프로젝트가 타당한지는 신뢰성이 누군가의 얼굴에 왜 반영되는지는 명확하지 않기 때문에 의심스럽다.

이 작업에 대한 데이터 세트를 수집하는 것은 사진에 레이블을 붙이는 사람들의 편견을 기록하는 것과 같다. 

만약 이 프로젝트를 통한 당신의 모델은 실제 사람들의 삶에 부정적인 영향을 미치면서 인간의 판단의 가장 나쁜 면들을 세탁하고 작동시킬 것이다. 

기술은 결코 중립일 수 없다. 만약 당신의 연구가 세상에 영향을 미친다면, 이 영향은 윤리적인 방향을 가진다.

기술적인 선택 또한 윤리적 선택이다. 당신의 작품이 뒷받침하기를 바라는 가치에 대해 항상 숙고해야 한다.

## 작업흐름의 세가지 부분 

`keras.datasets` 에서 올바른 데이터 세트를 가져와 일부 딥러닝 모델을 적합시킬 수 있다면 매우 편리할 것이다. 

하지만 불행히도 현실에서는 그렇지 않다. 문제부터 직면해야 한다. 

위에 나열된 문제처럼 머신러닝에 접근하고 문제를 해결하는 데 사용할 수 있는 보편적인 단계에 대해 알아본다.

머신러닝의 작업흐름은 크게 세 가지 부분으로 구성된다.

* **과제 정의** : 문제 영역과 고객이 질문한 내용을 뒷받침하는 논리를 이해한다. 데이터 집합을 수집하고 데이터가 나타내는 바를 파악한 후 성공을 측정하는 방법을 선택한다.

* **모델 개발** : 머신러닝 모델에서 데이터를 처리할 수 있도록 준비하고, 모델 평가 프로토콜과 간단한 기준선을 선택한다. 일반화 능력을 갖춘 첫 번째 모델을 훈련한 다음, 최대한의 일반화 성능을 달성할 때까지 모델을 정규화하고 조정한다.

* **모델 배치** : 이해관계자에게 작업물을 전달하고 웹 서버, 모바일 앱, 웹 페이지 또는 임베디드 장치로 모델을 전달하며 최초의 모델 성능을 모니터링하고, 차세대 모델 구축에 필요한 데이터를 수집하기 시작한다.



### 과제 정의

자신이 하고 있는 일의 맥락을 깊이 이해하지 않고서는 좋은 작업을 수행할 수 없다. 

* 당신의 고객은 왜 이 문제를 해결하려고 하는가? 

* 고객은 솔루션에서 어떤 가치를 창출할 수 있는가? 

* 모델이 어떻게 사용될 것이며 어떻게 부합될 것 같은가? 

* 어떤 종류의 데이터를 사용할 수 있거나 수집할 수 있는가? 

* 비즈니스 문제에 도입할 수 있는 머신러닝 과제는 무엇이 있는가?

#### 문제에 대한 프레임

머신러닝 문제를 구체화하기 위해서 일반적으로 이해 관계자들과의 많은 상세한 논의가 필요하다. 여기 여러분이 가지고 있어야 할 질문들이 있다.

* 입력 데이터는 어떻게 되는가? 당신은 무엇을 예측하려고 하는가? 예를 들어 영화 리뷰와 감상문에 대한 주석이 모두 있는 경우에만 영화 리뷰의 감상문을 분류하는 방법을 배울 수 있다. 이와 같이, 이 단계에서 데이터 가용성은 보통 제한 요소이다. 대부분의 경우 사용자가 직접 새 데이터셋을 수집하고 주석을 달아야 한다.

* 당신은 어떤 종류의 머신러닝 과제를 직면하고 있는가? 이항 분류? 다중 클래스 분류? 스칼라 회귀? 벡터 회귀? 멀티클래스 분류? 이미지 분할? 어떤 경우에는 머신러닝이 데이터를 이해하는 가장 좋은 방법이 아닐 수도 있고 그냥 평범한 통계 분석을 사용해야 하는 경우도 있을 것이다. 예를 들어,

 * 사진 검색 엔진 프로젝트는 다중 클래스 분류 작업.

 * 스팸 탐지 프로젝트는 이진 분류 작업.

 * 음악 추천 엔진은 딥러닝이 아니라 매트릭스 인수분해(협업 필터링)를 통해 더 잘 처리된다.

 * 신용카드 사기 적발 프로젝트는 이진 분류 작업.

 * 클릭률 예측 프로젝트는 스칼라 회귀 작업.

 * 쿠키 탐지는 이진 분류 작업이지만 처음 이미지에서 쿠키를 올바르게 잘라내기 위해서는 첫 번째 단계로 객체 탐지 모델이 필요.

 * 위성사진에서 새로운 고고학 유적지를 찾는 프로젝트는 이미지 유사성 순위 매기기 과제 (알려진 고고학 유적지와 가장 유사한 새로운 이미지를 검색.)


* 기존 솔루션은 어떤 모습인가? 아마도 당신의 고객은 이미 스팸 필터링이나 신용 카드 사기 탐지를 처리하는 수작업 알고리즘을 가지고 있을 것이다. 현재 쿠키 공장에서 컨베이어벨트를 수동으로 모니터링하고 불량 쿠키를 수동으로 제거하는 과정을 인간이 직접 처리하고 특정 아티스트를 좋아하는 사용자에게 보낼 노래 추천 재생 목록을 만드는 작업을 맡고 있을 것이다. 어떤 시스템이 이미 구축되어 있는지, 어떻게 작동하는지 확실히 이해해야 한다.

* 처리해야 할 특별한 제약이 있는가?
예를 들어, 스팸 탐지 시스템을 구축하는 앱이 철저하게  암호화되어 있으므로 스팸 탐지 모델은 최종 사용자의 전화기에서 작동해야 하며 MEAP 외부 데이터 세트에서 훈련되어야 한다. 그리고 쿠키 필터링 모델은 원격 서버보다는 공장에서 임베디드 장치가 실행되어야 하는 지연 시간 제약이 있을 것이다. 당신은 프로젝트의 전체 맥락을 이해해야 한다.

일단 조사를 마쳤으면, 당신은 `inputs`, `targets` 이 무엇인지, 그리고 문제가 어떤 종류의 머신러닝 과제로 매핑되는지 알아야 한다. 

이 단계에서 가설을 세운다.

* 입력이 주어지면 목표값을 예측할 수 있다는 가설을 세운다.

* 사용할 수 있는 데이터(또는 곧 수집할 데이터)가 입력과 목표값 간의 관계를 학습하는데 충분한 정보를 제공한다는 가설을 세운다.

언제까지나 가설일 뿐이며 검증될수 있고 안될 수도 있다. 머신러닝을 통해 모든 문제를 해결할 수 있는 것은 아니다.

입력 X와 목표 Y의 예를 종합했다고 해서 X가 Y를 예측하기에 충분한 정보를 포함하고 있다는 것을 의미하지는 않는다. 

예를 들어, 최근 가격을 감안할 때 주식 시장의 움직임을 예측하려고 한다면, 가격 이력은 예측 정보를 많이 포함하고 있지 않기 때문에 성공할 가능성이 낮다.

#### 데이터셋 수집

작업의 특성을 이해하고 입력과 목표가 무엇인지 알게 되면 대부분의 머신러닝 프로젝트에서 가장 힘들고 시간이 많이 걸리며 비용이 많이 드는 부분인 데이터 수집이 필요한 시점이다.

* 사진 검색 엔진 프로젝트에서는 먼저 분류할 레이블 세트를 선택해야 한다. 즉, 10,000개의 공통 이미지 범주에 안착한다. 그런 다음 이 세트의 레이블로 사용자가 업로드한 과거 이미지 수십만 개에 수동으로 태그를 지정해야 한다.

* 스팸 탐지 프로젝트는 사용자 채팅이 암호화되어 있어 해당 콘텐츠를 모델 훈련에 활용할 수 없다. 수만 개의 공개 소셜 미디어 게시물로 구성된 별도의 데이터 세트에 액세스하여 스팸, 불쾌감을 주는 내용 등의 태그를 수동으로 지정해야 한다.



* 음악 추천 엔진은 사용자의 "좋아요" 기록을 사용하면 된다. 새로운 데이터를 수집할 필요가 없다. 클릭률 예측 프로젝트도 마찬가지이다. 과거 광고에서 클릭률에 대한 광범위한 기록이 있으므로 새로운 데이터를 수집할 필요가 없다.

* 쿠키 분류 모델의 경우 수 만장의 이미지를 수집하기 위해 컨베이어 벨트 위에 카메라를 설치한 후 누군가가 수동으로 이 이미지에 레이블을 붙여야 한다. 이 방법을 사용하기 위해선 사람들을 훈련시켜야 한다.

* 위성사진 프로젝트는 고고학 팀이 기존 관심 장소의 데이터베이스를 수집해야 하며, 각 장소마다 다른 기상 조건에서 촬영한 기존 위성사진을 찾아야 한다. 좋은 모델을 얻으려면 수천 개의 다른 사이트가 필요하다.

모델의 일반화 기능은 거의 모델의 데이터 속성, 즉 보유한 데이터 수, 레이블의 안정성, 기능의 품질에 따라 학습된다는 것을 배웠다. 좋은 데이터 세트는 투자할 가치가 있는 자산이다. 프로젝트에 50시간을 더 할애할 경우 증분 모델링 개선 사항을 검색하는 것보다 더 많은 데이터를 수집하는 것이 가장 효과적인 방법이다.

알고리즘보다 데이터가 더 중요하다는 지적은 구글 연구진이 2009년에 발표한 'The Unreasonable Effectiveness of Data' 논문이 가장 유명하다. 이는 딥러닝이 유행하기 전에 나온 논문이지만, 놀랍게도 딥러닝의 부상은 데이터의 중요성을 더 크게 만들었다.

만약 지도 학습을 수행하는 경우 입력(예: 이미지)을 수집한 후 입력(예: 이미지 태그)에 대한 주석(예: 모델이 예측할 목표)이 필요하다.

때때로 음악 추천 작업이나 클릭률 예측 작업의 경우처럼 주석이 자동으로 검색될 수 있다. 하지만 대부분 데이터에 주석을 직접 달아야 한다. 이것은 노동력이 많이 드는 과정이다.

##### 데이터 주석에 투자

데이터 주석 공정에 따라 목표물의 퀄리티가 결정되고, 이는 다시 모델의 성능을 결정한다. 사용할 수 있는 옵션을 신중하게 고려해야한다.

* 데이터에 주석을 직접 달아야 하는가?

* 당신은 레이블을 모으기 위해 크라우드소싱 플랫폼을 사용해야 하는가?

* 데이터 레이블링 전문 회사의 서비스를 이용해야 하는가?

아웃소싱은 잠재적으로 시간과 비용을 절약할 수 있지만 통제력을 빼앗는다. 크라우드소싱 플랫폼을 사용하는 것은 비용이 많이 들고 잘 확장될 수 있지만, 주석들이 중구난방일 수 있다.

최상의 옵션을 선택하려면 작업 중인 제약 조건을 고려해야한다.

* 데이터 레이블 작성자가 전문가인가? 아니면 데이터에 주석을 달 수 있는 사람이 있는가? 고양이 vs 개 이미지 분류 문제의 레이블은 누구나 선택할 수 있지만 개 품종 분류 작업의 레이블은 전문 지식이 필요하다.

* 데이터 주석에 대한 전문 지식이 있다면, 그것을 하도록 사람들을 훈련시킬 수 있는가? 그렇지 않다면, 관련 전문가와 어떻게 접촉할 수 있는가?



* 당신은 전문가들이 어떻게 주석을 다는지 이해할 수 있는가? 그렇지 않으면 데이터 세트를 블랙박스로 취급해야 하며 MEAP 수동 기능 엔지니어링을 수행할 수 없다. 이는 중요하지는 않지만 제한적일 수 있다.

데이터에 레이블을 붙이기로 결정한 경우 주석을 기록하는 데 사용할 소프트웨어를 스스로 찾거나, 당신이 직접 그 소프트웨어를 개발해야 할 수도 있다. 생산적인 데이터 주석 소프트웨어는 많은 시간을 절약할 수 있으므로 프로젝트 초기에 투자할 가치가 있다.

##### 비대표적인 데이터 주의

머신러닝 모델은 이전에 본 것과 비슷한 입력만 이해할 수 있다. 따라서 훈련에 사용되는 데이터가 생산 데이터를 대표해야 한다. 이 문제는 모든 데이터 수집의 기반에서 우려된다.

사용자가 음식 이름을 알기 위해 사진을 찍을 수 있는 앱을 개발 중이라고 가정해 보자. 식도락가들에게 인기 있는 이미지 공유 소셜 네트워크의 사진을 사용하여 모델을 훈련시킨다. 배포 시간이 다가오면 화난 사용자들이 앱이 10번 실행되었을 때 8번이 오답이 나온다며 피드백을 쏟아낸다. 테스트 세트의 정확도는 90%를 훨씬 넘었는데 말이다. 

사용자가 업로드한 데이터를 살펴보면 랜덤 스마트폰으로 찍은 랜덤 레스토랑의 모바일 사진 업로드가 전문가가 촬영한 밝은 화질의 사진과 전혀 다르다는 것을 알 수 있다. 

**즉 훈련 데이터는 생산 데이터를 대표하지 않는다**는 것을 단적으로 보여주는 예이다.

가능하면 모델이 사용될 환경에서 직접 데이터를 수집하는 것이 좋다. 영화 감상 분류 모델은 리뷰 어플의 리뷰나 소셜 네트워크 감상문이 아닌 새로운 IMDB 리뷰가 사용되어야 한다. 

소셜 네트워크의 감상문을 평가하려면 데이터 생산자가 예상하는 사용자와 유사한 사용자 집합에서 내용을 수집하여야 한다. 

생산 데이터에 대한 훈련이 가능하지 않다면 훈련 데이터와 생산 데이터가 어떻게 다른지 완전히 이해하고 이러한 차이를 적극적으로 수정해야 한다.

**※ 컨셉 드리프트**

```
위 문제와 관련해서 당신이 알아야 할 현상은 컨셉 드리프트(concept drift)이다. 

거의 모든 실제 문제, 특히 사용자 생성 데이터를 다루는 문제에서 발생한다. 

컨셉 드리프트는 시간이 지남에 따라 생산 데이터의 속성이 변경되어 모델 정확도가 점차 저하될 때 발생한다. 

그 예로 2013년에 훈련된 음악 추천 엔진은 오늘날 그다지 효과적이지 않을 수 있다. 

마찬가지로, 앞서 했던 IMDB 데이터셋도 2011년에 수집된 데이터이며 이 데이터셋으로 훈련된 모델은 

시간이 지남에 따라 어휘, 표현 및 영화 장르가 발전함에 따라 2012년의 리뷰와 비교하여 

2020년의 리뷰에서는 제대로 성능 발휘를 못할 가능성이 높다. 

컨셉 드리프트는 신용 카드 사기 탐지와 같은 적대적인 맥락에서 특히 극심하다. 사기 패턴은 계속 변하기 때문이다.

이 현상을 처리하기 위해서는 지속적인 데이터 수집, 주석 및 모델 재훈련이 필요하다.
```

**미래를 예측하기 위해 과거 데이터에 대해 훈련된 머신러닝을 사용하는 것은 미래가 과거와 같이 행동할 것이라는 가정을 하는 것이다.**

#### 데이터 이해

데이터 세트를 블랙박스로 취급하는 것은 매우 나쁜 관행이다. 모델을 훈련하기 전에 데이터를 탐색하고 시각화하여 예측 가능한 요소에 대한 통찰력을 얻고 잠재적인 문제를 선별해야 한다.

* 데이터에 이미지 또는 자연어 텍스트가 포함된 경우 몇 가지 샘플(및 해당 레이블)을 직접 살펴봐야한다.

* 데이터에 숫자 형상이 포함되어 있는 경우 형상 값의 히스토그램을 그래프로 표시하여 사용된 값의 범위와 다른 값의 빈도를 파악하는 것이 좋다.

* 데이터에 위치 정보가 포함되어 있으면 지도에 표시한다.

* 일부 샘플에 결측값이 있는가? 이 경우 데이터를 준비할 때 이 문제를 해결해야 한다.

* 분류 문제인 경우 데이터에 있는 각 클래스의 인스턴스 수를 인쇄한다. 클래스가 대략적으로 동등하게 표현되지 않으면 불균형을 고려해야 한다.

* 타겟 누출 여부: 데이터에 운영 환경에서 사용할 수 없는 대상에 대한 정보를 제공하는 기능이 있는지 확인한다.


#### 성공의 척도 선택

무언가를 통제하기 위해서는 그것을 관찰할 수 있어야 한다. 프로젝트에서 성공을 거두려면 먼저 성공이 무엇인지 정의해야 한다. 

정확성과 기억력? 고객 유지율? 성공을 위한 지표는 프로젝트 전반에 걸쳐 하게 될 모든 기술적 선택을 안내할 것이다.

머신러닝 성공 지표의 다양성과 이들이 서로 다른 문제 영역과 어떻게 관련되는지 파악하려면 *Kaggle*에서 데이터 과학 대회를 검색하는 것이 도움이 된다. 다양한 문제와 평가 지표가 있다.

### 모델 개발

진행 상황을 어떻게 파악할 것인지 알고 나면 모델 개발을 시작할 수 있다. 

대부분의 튜토리얼과 연구 프로젝트는 이것이 이미 수행된 것으로 가정되는 문제 정의 및 데이터 세트 수집을 건너뛰고 다른 사람이 처리하는 것으로 가정하는 모델 배치 및 유지 보수를 건너뛴다고 가정한다. 

사실 모델 개발은 작업흐름의 한 단계일 뿐이고 가장 어려운 것은 아니다.

#### 데이터 준비

앞에서 배웠듯이 딥러닝 모델은 일반적으로 원시 데이터를 수집하지 않는다. 데이터 전처리는 원시 데이터를 신경망에 더 잘 적응하도록 만드는 것을 목표로 한다.

여기에는 벡터화, 정규화 또는 결측값 처리가 포함된다. 많은 사전 처리 기술은 도메인마다 다르다(예: 텍스트 데이터 또는 이미지 데이터).

##### 벡터화

신경망의 모든 입력과 대상은 일반적으로 부동소수점 데이터의 텐서(또는 특정한 경우 정수나 문자열의 텐서)여야 한다. 

소리, 이미지, 텍스트 등 필요한 데이터가 먼저 텐서로 변환해야 하는데 이 단계를 데이터 벡터화라고 한다. 

##### 정규화

상대적으로 큰 값(예: 네트워크의 초기 가중치보다 훨씬 큰 여러 자리 정수)을 사용하는 신경망 데이터에 입력하는 것은 안전하지 않다. 이렇게 하면 대규모 그라데이션 업데이트가 트리거되어 네트워크가 수렴되지 않을 수 있다. 

네트워크에서 보다 쉽게 학습하려면 데이터에 다음과 같은 특성이 있어야 한다.

* 작은 값 사용 - 일반적으로 대부분의 값은 0-1 범위.

* 균일성 - 즉, 모든 피쳐가 거의 동일한 범위의 값을 가진다.

또한 다음과 같은 엄격한 정규화 방법은 항상 필요한 것은 아니지만 도움이 될 수 있다.

* o의 평균을 가지도록 각 형상을 독립적으로 정규화.

* 표준 편차가 1이 되도록 각 형상을 독립적으로 정규화. 

NumPy 배열에서는 이 작업을 쉽게 수행할 수 있다.

```
x -= x.mean(axis=0)
x /= x.std(axis=0)
```

##### 결측값 처리

때때로 데이터에 결측값이 있을 수 있다. 

결측값이 있는 특성을 완전히 없앨수도 있지만 반드시 없앨 필요는 없다.

*  범주형인 경우 "값이 누락됨"을 의미하는 새 범주를 작성하는 것이 안전하다. 모델은 이것이 내포하는 의미를 자동으로 학습한다.


* 숫자인 경우, 데이터 집합의 특성에 대한 평균값 또는 중위값으로 바꾸는 것을 고려한다.

테스트 데이터에 범주형 결측값이 있을 것으로 예상되지만 네트워크가 결측값 없이 데이터에 대해 학습된 경우에는 누락된 항목이 있는 훈련 샘플을 인위적으로 생성해야 한다. 일부 훈련 샘플을 여러 번 복사하고 훈련 데이터에서 누락될 것으로 예상되는 범주형 특성 중 일부를 삭제해야 한다.

#### 검증 프로토콜 선택

모델의 목적은 일반화를 달성하는 것이며, 모델 개발 프로세스 전반에 걸쳐 내릴 모든 모델링 결정은 일반화 성과를 측정하기 위한 검증 지표에 의해 안내된다. 

검증 프로토콜의 목표는 실제 생산 데이터에서 선택한 성공 지표(예: 정확도)를 정확하게 추정하는 것이다. 그 과정의 신뢰성은 유용한 모델을 구축하는 데 매우 중요하다.

* 홀드아웃 교차 검증 수행 - 데이터가 많을 때 사용하는 방법

* K-폴드 교차 검증 수행 - 샘플 수가 너무 적어서 홀드아웃 검증을 신뢰할 수 없을 때 사용하는 방법

* 반복 K-폴드 검증 수행 - 데이터가 거의 없을 때 매우 정확한 모델 평가 수행 방법

이것들 중 하나만 골라 수행한다.
 
대부분의 경우 첫 번째 방법은 충분히 효과가 있을 것이다. 항상 검증 세트의 대표성에 유의하고 훈련 세트와 검증 세트 사이에 중복 샘플이 없도록 주의해야한다.

#### 기준선 능가

모델 자체에 대한 작업을 시작하면 통계적 검증능력을 달성하는 것이 초기 목표다.
 
즉, 간단한 기준선을 능가할 수 있는 작은 모델을 개발하는 것이다.

이 단계에서 가장 중요한 세 가지 사항은 다음과 같다.

* 특성 엔지니어링을 통해 정보를 제공하지 않는 특성을 필터링하고 문제에 대한 지식을 활용하여 유용하게 사용할 수 있는 새로운 특성을 개발할 수 있다.

* 올바른 이전 모델 구조 선택 : 사용할 모델 구조 유형은 무엇인가? 촘촘하게 연결된 네트워크, 컨브넷, 반복적인 신경 네트워크, 트랜스포머? 딥러닝은 과제를 위한 좋은 접근법인가, 아니면 다른 것을 사용해야 하는가?


* 적합한 훈련 구성 선택 : 어떤 손실 함수를 사용해야 하는가? 배치 크기와 학습률은 어떻게 되는가?

#### 참고: 올바른 손실 함수 선택

문제에 대한 성공을 측정하는 메트릭에 대해 직접 최적화하지 못하는 경우가 많다.
메트릭을 손실 함수로 바꾸는 쉬운 방법이 없을 때도 있다. 

결국 손실 함수는 데이터의 작은 배치(이상적으로 손실 함수는 단일 데이터 포인트만큼만 계산 가능해야 함)가 주어져야 하며, 역전파를 사용하여 네트워크를 훈련시킬 수 없어야 한다. 

예를 들어, 널리 사용되는 분류 지표 ROC AUC는 직접 최적화될 수 없다. 따라서 분류 작업에서 교차 엔트로피와 같은 ROC AUC의 프록시 메트릭에 최적화하는 것이 일반적이다. 

일반적으로 교차 엔트로피가 낮을수록 ROC AUC가 더 높아지기를 바랄 수 있다. 

밑의 표는 몇 가지 일반적인 문제 유형에 대한 마지막 계층 활성화 및 손실 함수를 선택하는 데 도움이 될 수 있다.

##### 모델에 적합한 마지막 계층 활성화 및 손실 함수 선택

<table>
 <tr>
  <th colspan=6>모델에 적합한 마지막 계층 활성화 및 손실 함수 선택</th>
 </tr>
 <tr>
  <td>
   <th>문제 유형</th>
  </td>

  <td>
   <th>마지막 층 Activation</th>
  </td>

  <td>
   <th>손실 함수</th>
  </td>
 </tr>
 <tr>
  <td>
   <th>이진 분류</th>
  </td>

  <td>
   <th>sigmoid</th>
  </td>

  <td>
   <th>binary_crossentropy</th>
  </td>
 </tr>
 <tr>
  <td>
   <th>다중 클래스 단일 레이블 분류</th>
  </td>

  <td>
   <th>softmax</th>
  </td>

  <td>
   <th>categorical_crossentropy</th>
  </td>
 </tr>
 <tr>
  <td>
   <th>다중 클래스 다중 레이블 분류</th>
  </td>

  <td>
   <th>sigmoid</th>
  </td>

  <td>
   <th>binary_crossentropy</th>
  </td>
 </tr>
 <tr>
  <td>
   <th>임의값으로 회귀</th>
  </td>

  <td>
   <th>None</th>
  </td>

  <td>
   <th>mse</th>
  </td>
 </tr>
</table>

대부분의 문제에서 시작할 수 있는 기존 템플릿이 있다. 

선행 모델의 기술을 조사하여 가장 잘 수행할 수 있는 특성 엔지니어링 기술과 모델 구조를 식별해야 한다. 통계적 힘을 얻는 것이 항상 가능한 것은 아니다. 

합리적인 구조를 여러 번 시도해도 단순한 기준선을 넘을 수 없다면 입력 데이터에 질문에 대한 답이 없는 것일 수 있다. 

두 가지 가설을 세운다.

* 입력이 주어지면 출력을 예측할 수 있다는 가설을 세운다.


* 사용 가능한 데이터가 입력과 출력 간의 관계를 학습하는 데 충분한 정보를 제공한다는 가설을 세운다.

이 가설들이 거짓일 가능성이 높으며, 이 경우 당신은 처음부터 다시 시작해야 한다.

#### 스케일업: 과대적합 모델 개발

일단 통계적 힘을 가진 모델을 얻으면, 질문은 여러분의 모델이 충분히 강력하냐는 것이다. 그 모델은 문제를 적절하게 해결할 충분한 레이어와 파라미터를 가지고 있는가? 

이상적인 모델은 과소적합과 과대적합 사이의 경계에 서 있는 모델이다. 이 경계가 어디에 있는지 알아내려면 먼저 경계를 넘어봐야 알수 있다.

얼마나 큰 모델이 필요한지 알아내려면 지나치게 적합한 모델을 개발해야 한다.

1. 레이어를 추가

2. 층의 유닛 수를 크게

3. 더 많은 에포크 실행

훈련 손실 및 검증 손실은 물론 관심 있는 메트릭에 대한 훈련 및 검증 값도 항상 모니터링한다. 검증 데이터에 대한 모델의 성능이 저하되기 시작하면 과대적합이 이루어진 것이다.

#### 모델 정규화 및 조정

일단 통계적 힘을 얻고 과대적합을 할 수 있게 되면 당신은 올바른 길을 가고 있다는 것을 알게 된다. 이때 일반화 성능을 최대화하는 것이 목표이다.

이 단계에서는 모델이 최대한 좋은 결과를 얻을 때까지 반복적으로 모델을 수정하고 훈련하고 검증 데이터(현 시점에서 테스트 데이터가 아님)를 평가한 다음 다시 수정하고 반복한다. 

다음과 같은 몇 가지 방법을 시도해 보면 좋다.

* 다른 모델 구조를 시도하거나 레이어를 추가 또는 제거한다.

* `Dropout`을 적용한다. 모델의 크기가 작으면 L1 또는 L2 규제를 추가한다.

* 최적의 구성을 찾기 위해 다양한 하이퍼 파라미터(예: 계층당 유닛 수 또는 학습률)를 사용해본다.

* 선택적으로 데이터 큐레이션 또는 특성 엔지니어링을 반복할 수 있다. 더 많은 데이터를 수집하고 주석을 달거나, 더 나은 특성 개발하거나, 유용한 것으로 보이지 않는 특성을 제거할 수도 있다.

`Keras`와 같은 자동화된 하이퍼 파라미터 튜닝 소프트웨어를 사용하여 이 작업의 상당 부분을 자동화할 수 있다.

검증 프로세스의 피드백을 사용하여 모델을 조정할 때마다 검증 프로세스에 대한 정보가 모델에 학습된다. 

몇 번만 반복해도 무해하지만, 여러 반복에 걸쳐 체계적으로 수행되면 검증 데이터에 대해 직접 훈련 받은 모델이 없음에도 불구하고 결국 모델이 검증 프로세스에 과대적합하게 된다. 

이것은 평가 과정의 신뢰성을 떨어뜨린다.

만족스러운 모델을 개발했으면 사용 가능한 모든 데이터(훈련 및 검증)에 대해 최종 생산 모델을 훈련하고 테스트 세트에서 마지막으로 평가할 수 있다. 

테스트 세트의 성능이 검증 데이터에서 측정된 성능보다 훨씬 더 나쁜 것으로 판명되면 이는 검증 절차를 신뢰할 수 없거나 모델의 매개 변수를 조정하는 동안 검증 데이터에 과대적합하기 시작했음을 의미할 수 있다. 

이 경우 K-폴드 반복 유효성 검사와 같은 보다 안정적인 평가 프로토콜로 전환할 수 있다.

### 모델 배포

귀하의 모델은 테스트 세트에 대한 최종 평가를 성공적으로 마쳤다. 이제 효율적으로 사용하고 생산적인 삶을 시작할 준비가 되었다.

#### 이해 관계자에게 작업 설명 및 기대치 설정

성공과 고객의 신뢰는 지속적으로 고객의 기대에 부응하거나 그 이상을 달성하는 것이다.

실제로 제공하는 시스템은 절반에 불과한다. 나머지 절반은 출시 전 적절한 기대치를 설정하고 있다.

AI 시스템에 대한 비전문가들의 기대는 종종 비현실적이다. 

예를 들어, 그들은 시스템이 프로젝트를 "이해"하고 프로젝트 맥락에서 인간과 같은 상식을 행사할 수 있다고 기대한다. 


이 문제를 해결하려면 실패한 모델의 몇 가지 예제를 보여 주는 것이 좋다(예: 잘못 분류된 표본).

대부분의 머신러닝 모델은 인간이 만든 레이블에 근접하도록 훈련되었기 때문에 거의 완벽한 모델에 도달하지 못한다. 모델 성능 기대치를 명확히 전달해야 한다. 

"모델은 98%의 정확도를 가지고 있으며"와 같은 추상적인 문장을 사용하는 것을 피하고 거짓 음성 비율과 거짓 양성 비율에 대해 이야기하는 것을 선호한다. 

"이러한 설정을 사용하면 부정 행위 탐지 모델은 5%의 거짓 음성 비율과 2.5%의 거짓 양성 비율을 갖는다. 매일 평균 200건의 유효거래가 사기행위로 지정되어 수작업 검토를 위해 발송되고, 평균 14건의 사기거래가 누락되었다. 평균 266건의 부정거래가 적발될 것이다." 

모델의 성능 측정 기준을 비즈니스 목표와 명확하게 연관시켜야 한다.

또한 주요 매개 변수(예: 플래그를 지정해야 하는 확률 임계값(임계값이 다르면 거짓 음수 및 거짓 긍정 비율이 다름)를 선택할 것인지 이해 관계자와 논의해야 한다.

#### 추론 모델 배포

머신러닝 프로젝트는 훈련된 모델을 저장할 수 있는 콜랩 노트북에 도달해도 끝나지 않는다. 훈련 중에 조작한 것과 동일한 파이썬 모델 객체를 프로덕션으로 넣는 경우는 거의 없다.

먼저 Python이 아닌 다른 것을 통해 모델을 내보는 것이 좋다.

* 운영 환경에서 Python을 전혀 지원하지 않을 수 있다. 예를 들어, Python이 모바일 앱이나 임베디드 시스템인 경우이다.


* 앱이 Python이 아닌 경우(JavaScript, C++ 등) 모델을 서비스하기 위해 Python을 사용하면 상당한 오버헤드가 발생할 수 있다.

두번째로 생산 모델은 훈련용이 아니라 예측(추론이라고 하는 단계) 출력에만 사용되므로 모델을 더 빠르게 만들고 메모리 공간을 줄일 수 있는 다양한 최적화를 수행할 수 있다.

이제 사용 가능한 다양한 모델 구축 옵션을 간단히 살펴본다.

##### REST API로 모델 배포

이것은 아마도 모델을 제품으로 바꾸는 일반적인 방법일 것이다. 

서버나 클라우드 인스턴스에 TensorFlow를 설치하고 REST API를 통해 모델의 예측을 쿼리한다. 

플라스크(또는 다른 파이썬 웹 개발 라이브러리)와 같은 것을 사용하여 자신만의 서빙 앱을 구축하거나 TensorFlow의 자체 라이브러리를 사용하여 모델을 API로 제공할 수 있다.

[TensorFlow 서빙](https://www.tensorflow.org/tfx/guide/serving)을 사용하여 Keras 모델을 몇 분 내에 배포할 수 있다.

다음과 같은 경우 이 배포 설정을 사용해야 합니다.

* 모델의 예측을 소비할 애플리케이션은 (분명히) 인터넷에 신뢰할 수 있는 액세스를 갖게 될 것이다. 예를 들어 응용 프로그램이 모바일 응용 프로그램인 경우 원격 API에서 예측을 제공한다는 것은 응용 프로그램을 비행기 모드나 연결 지연 환경에서 사용할 수 없음을 의미한다.

* 애플리케이션에는 엄격한 대기 시간 요구사항이 없다. 요청, 추론 및 응답 왕복에는 일반적으로 약 500ms가 소요된다.

* 추론을 위해 전송된 입력 데이터는 그다지 민감하지 않다. 즉, 데이터는 모델에서 확인할 필요가 있으므로 해독된 형태로 서버에서 사용할 수 있어야 한다(HTTP 요청 및 응답에 SSL 암호화를 사용해야 함).

예를 들어 이미지 검색 엔진 프로젝트, 음악 추천 시스템, 신용카드 사기 탐지 프로젝트, 위성 이미지 프로젝트는 모두 REST API를 통해 서비스하기에 적합하다.

REST API로 모델을 배포할 때 중요한 질문은 코드를 직접 호스팅할지 아니면 완전히 관리되는 타사 클라우드 서비스를 사용할지 여부이다. 

예를 들어 구글 제품인 클라우드 AI 플랫폼은 텐서플로우 모델을 구글 클라우드 스토리지(GCS)에 업로드하면 이를 쿼리할 수 있는 API를 제공한다. 

일괄 처리 예측, 로드 밸런싱 및 스케일링과 같은 많은 세부 사항을 처리한다.

##### 장치에 모델 배포

스마트폰, 로봇의 내장형 ARM CPU 또는 작은 장치의 마이크로컨트롤러 등 해당 애플리케이션을 실행하는 동일한 장치에 모델을 사용해야 할 수도 있다. 

예를 들어, 이미 카메라에서 실행되는 작은 딥러닝 모델인 사람과 얼굴을 자동으로 감지할 수 있는 카메라를 본 적이 있을 것이다.

다음과 같은 경우 이 설정을 사용해야 한다.

* 모델에 엄격한 지연 시간 제약이 있거나 연결성이 낮은 환경에서 실행해야 한다. 증강 현실 애플리케이션을 구축하는 경우 원격 서버를 쿼리하는 것은 실행 가능한 옵션이 아니다.

* 모델을 대상 장치의 메모리 및 전력 제약 조건에서 실행할 수 있을 정도로 충분히 작게 만들 수 있다.

* 런타임 효율성과 정확성 사이에는 항상 균형이 있기 때문에 메모리 및 전력 제약으로 인해 대형 GPU에서 실행할 수 있는 최상의 모델만큼 좋지 않은 모델을 제공해야 하는 경우가 많다.

* 입력 데이터는 중요하므로 원격 서버에서 해독할 수 없다.

예를 들어, 스팸 탐지 모델은 최종 사용자의 스마트폰에서 채팅 앱의 일부로 실행되어야 하는데 이는 메시지가 암호화되어 원격으로 호스팅된 모델에서 전혀 읽을 수 없기 때문이다. 

마찬가지로 불량 쿠키를 탐지하는 모델도 엄격한 대기 시간 제약이 있어 공장에서 실행해야 한다. 다행히 이 경우 전력이나 공간 제약이 없어 GPU에서 실제로 모델을 실행할 수 있다.

스마트폰이나 임베디드 장치에 Keras 모델을 배포하려면 [TensorFlow Lite](https://www.tensorflow.org/lite)를 사용해야 한다. 

ARM64 기반 컴퓨터, 라즈베리 파이 또는 특정 마이크로컨트롤러 뿐만 아니라 Android 및 iOS 스마트폰에서 실행되는 효율적인 프레임워크이다. 

Keras 모델을 TensorFlow Lite 형식으로 바로 전환할 수 있는 변환기가 포함되어 있다.

##### 브라우저에서 모델 배포

딥 러닝은 브라우저 기반 또는 데스크톱 기반 자바스크립트 응용 프로그램에서 자주 사용된다. 

응용 프로그램이 REST API를 통해 원격 모델을 쿼리하는 것이 보통 가능하지만 대신 사용자의 컴퓨터에서 직접 모델을 실행할 수 있는 주요 이점이 있다.

다음 경우에 이 설정을 사용한다.


* 최종 사용자에게 오프로드하여 서버 비용을 크게 절감할 수 있다.


* 입력 데이터는 최종 사용자의 컴퓨터 또는 전화기에 남아 있어야 한다. 예를 들어 스팸 탐지 프로젝트에서 채팅 앱의 웹 버전과 데스크톱 버전(JavaScript로 작성된 크로스 플랫폼 앱으로 구현됨)은 로컬에서 실행되는 모델을 사용해야 한다.

* 애플리케이션에는 엄격한 지연 시간 제약이 있다. 최종 사용자의 노트북이나 스마트폰에서 실행되는 모델은 서버의 대형 GPU에서 실행되는 모델보다 속도가 느릴 수 있다.

* 모델이 다운로드되고 캐시된 후에도 연결 없이 계속 작동하려면 앱이 필요하다.

물론 모델이 사용자의 노트북이나 스마트폰의 CPU, GPU 또는 RAM을 독점하지 않을 정도로 작은 경우에만 이 옵션을 사용해야 한다. 

또한 전체 모델이 사용자의 장치에 다운로드되므로 모델에 대해 비밀로 유지할 필요가 없도록 해야 한다. 

훈련된 딥러닝 모델이 주어지면 일반적으로 훈련 데이터에 대한 일부 정보를 복구할 수 있다는 사실에 유의해야한다. 중요한 데이터에 대해 훈련된 모델은 공개하지 않는 것이 좋다.

자바스크립트에서 모델을 배포하기 위해 텐서플로우 생태계는 많은 하위 수준의 TensorFlow API를 구현한다. 저장된 Keras 모델을 `TensorFlow.js`로 쉽게 가져와 브라우저 기반 JavaScript 앱 또는 데스크톱 Electronic 앱의 일부로 쿼리할 수 있다.

##### 추론 모델 최적화

사용 가능한 전력 및 메모리(스마트폰 및 임베디드 장치)에 엄격한 제약이 있는 환경이나 대기 시간이 짧은 애플리케이션에 배포할 때 추론을 위해 모델을 최적화하는 것이 특히 중요하다.

`TensorFlow.js`로 가져오거나 TensorFlow Lite로 내보내기 전에 항상 모델을 최적화해야 하는 것이 중요하다.

적용할 수 있는 기본 최적화 기법

* 가중치 가지치기(Weight pruning) : 가중치 텐서의 모든 계수가 예측에 동일하게 기여하는 것은 아니다. 가장 중요한 항목만 유지하면 모델의 계층에서 매개변수 수를 크게 줄일 수 있다. 따라서 성능 메트릭에서 적은 비용으로 모델의 메모리 및 컴퓨팅 설치 공간을 줄일 수 있다. 적용할 가지치기 양을 조정하면 크기와 정확도 사이의 균형을 조정할 수 있다.

* 가중치 정량화(Weight quantization) : 딥 러닝 모델은 단일 정밀 부동 소수점(float32 ) 가중치를 사용하여 훈련된다. 그러나 가중치를 8비트 부호 정수(int8)로 정량화하면 4배 작지만 원래 모델의 정확도에 가까운 추론 전용 모델을 얻을 수 있다.

TensorFlow 생태계는 Keras API와 긴밀하게 통합된 가중치 가지치기 및 정량화 [툴킷](https://www.tensorflow.org/model_optimization)을 포함한다.

####  모델 모니터링

추론 모델을 내보내고 이를 애플리케이션에 통합한 후 프로덕션 데이터에 대해 시운전을 수행했다. 모델이 예상대로 작동한다. 

유닛 테스트 및 상태 모니터링 코드를 완벽하게 작성했다. 이제 실제 운영에 투입할 차례다.

모델을 구축한 후에는 모델의 동작, 새 데이터에 대한 성능, 나머지 애플리케이션과의 상호 작용 및 궁극적으로 비즈니스 메트릭에 미치는 영향을 계속 모니터링해야 한다.

* 새로운 음악 추천 시스템을 구축한 후 온라인 라디오에 대한 사용자 참여가 증가하는가? 감소하는가? 새로운 클릭률 예측 모델로 전환 후 평균 광고 클릭률이 증가했는가? 랜덤 A/B 테스트를 사용하여 다른 변경으로 인해 모델에 영향을 주지 않도록 분리하는 것을 고려해야한다.

* 가능하면 생산 데이터에 대한 모델의 예측에 대해 정기적으로 수동 감사를 실시한다. 일반적으로 데이터 주석과 동일한 인프라를 재사용할 수 있다. 생산 데이터의 일부를 수동으로 주석을 달도록 전송하고 모델의 예측값을 새 주석과 비교한다. 예를 들어 이미지 검색 엔진과 불량 쿠키 분류 모델 시스템에 대해 이 작업을 수행해야 한다.

* 수동 감사가 불가능한 경우 사용자 설문 조사와 같은 대체 평가 방법을 고려해야한다.

#### 모델 유지 관리

마지막으로, 영원한 모델은 없다. 컨셉 드리프트에 대해 이미 배웠다. 시간이 지남에 따라 생산 데이터의 특성이 바뀌어 모델의 성능과 관련성이 점차 저하된다. 

모델이 출시되자마자 모델을 대체할 다음 세대를 훈련할 준비를 해야한다.

* 생산 데이터의 변화를 주의하세요. 새로운 기능을 사용할 수 있습니까? 레이블 세트를 확장해야 합니까, 그렇지 않으면 편집해야 합니까?

* 데이터를 계속 수집하고 주석을 달 수 있으며 시간이 지남에 따라 주석 파이프라인을 계속 개선할 수 있다. 특히 현재 모델에 대해 분류하기 어려운 표본을 수집하는 데 주의해야 한다. 이러한 표본은 성능을 향상시키는 데 도움이 될 가능성이 높다.

이것으로 기억해야 할 많은 머신러닝의 보편적인 작업 흐름을 마무리한다. 

전문가가 되기 위해서는 시간과 경험이 중요하지만 이것을 배움으로써 훨씬 더 현명해졌다. 이제 머신러닝 프로젝트에 수반되는 전체 스펙트럼이라는 큰 그림에 익숙해졌다.

## 요약

* 새 머신러닝 프로젝트를 수행할 때 먼저 당면한 문제를 정의한다.
  * 최종 목표는 무엇이고 제약은 무엇인지를 알고 보다 광범위한 맥락을 이해해야 한다.

  * 데이터 세트를 수집하고 주석을 달 수 있다. 데이터를 자세히 이해해야 한다.

  * 문제에 대한 성공 여부를 측정하는 방법, 검증 데이터에 대해 어떤 메트릭스를 모니터링할 것인지 선택해야한다.

* 문제를 이해하고 적절한 데이터 세트를 확보했으면 모델을 개발한다.
  * 데이터를 준비한다.

  * 평가 프로토콜을 선택한다. 홀드-아웃 검증? K-폴드 검증? 검증에 사용할 데이터 부분은 어느 정도인가?

  * 통계 능력 달성: 단순한 기준선 능가.

  * 스케일업: 과대적합할 수 있는 모델을 개발한다. 
 
  * 검증 데이터의 성능에 따라 모델을 정규화하고 하이퍼 파라미터를 조정할 수 있다.

* 모델이 준비되고 테스트 데이터에 대해 우수한 성능을 제공하면 이제 다음과 같이 배포한다.
  * 먼저 이해관계자들과 적절한 기대치를 설정한다.

  * 추론을 위해 최종 모델을 최적화하고, 모델을 다음 주소로 전달한다. (웹 서버, 모바일, 브라우저, 배포 환경이
포함된 장치 등)

  * 모델의 생산 성능을 모니터링하고 데이터를 계속 수집하여 차세대 모델을 개발할 수 있다.
